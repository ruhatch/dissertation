% Template for a Computer Science Tripos Part II project dissertation
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[nameinlink]{cleveref}
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{verbatim}
\usepackage{docmute}   % only needed to allow inclusion of proposal.tex
\usepackage{todonotes}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{tabularx}
\usepackage{tikz}
\usetikzlibrary{trees}

%%%%%%% Using Minted Package for Code Listings %%%%%%%
\usepackage{minted}
\usemintedstyle{colorful}

\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable

\newcommand{\mytodo}{\todo[inline, color=green!40]}

\begin{document}

\bibliographystyle{plain}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title


\pagestyle{empty}

\rightline{\LARGE \textbf{Rupert Horlick}}

\vspace*{60mm}
\begin{center}
\Huge
\textbf{Encrypted Keyword Search Using Path ORAM on MirageOS} \\[5mm]
Computer Science Tripos -- Part II \\[5mm]
Homerton College \\[5mm]
\today  % today's date
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\pagestyle{plain}

\chapter*{Proforma}

{\large
\begin{tabular}{ll}
Name:               & \bf Rupert Horlick                       \\
College:            & \bf Homerton College                     \\
Project Title:      & \bf Encrypted Keyword Search Using \\
& \bf Path ORAM on MirageOS \\
Examination:        & \bf Computer Science Tripos -- Part II, July 2016  \\
Word Count:         & \bf \footnotemark[1]
                      (well less than the 12000 limit)  \\
Project Originator: & Dr Nik Sultana                    \\
Supervisors:         & Dr Nik Sultana \& Dr Richard Mortier                    \\
\end{tabular}
}
\footnotetext[1]{This word count was computed
by \texttt{detex diss.tex | tr -cd '0-9A-Za-z $\tt\backslash$n' | wc -w}
}
\stepcounter{footnote}


\section*{Original Aims of the Project}

% Give a 100 word summary of what was to be achieved by the project, i.e. secure searchable encrypted documents

\section*{Work Completed}



\section*{Special Difficulties}



\newpage
\section*{Declaration}

I, Rupert Horlick of Homerton College, being a candidate for Part II of the Computer
Science Tripos, hereby declare
that this dissertation and the work described in it are my own work,
unaided except as may be specified below, and that the dissertation
does not contain material that has already been used to any substantial
extent for a comparable purpose.

\bigskip
\leftline{Signed [signature]}

\medskip
\leftline{Date [date]}

\tableofcontents

\listoffigures

\todototoc
\listoftodos

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% now for the chapters

\pagestyle{headings}

\chapter{Introduction}

% Give an overview of the problem - similar to the beginning of the project proposal

% Talk about increasing use of cloud computing

% Talk about loss of ability to search efficiently over documents

% Define threat model clearly

% Talk about solutions based on symmetric encryption

% Explain why these fail and what the consequences are

% Discuss ORAM as a solution to this problem

% Describe other work in the area of ORAM etc.

\section{Motivation}

Cloud computing is becoming ubiquitous, with more than an exabyte of data estimated to be stored in the cloud. For large businesses, a private cloud can be a cost effective way to keep data isolated, but as public cloud services become ever cheaper, even these businesses could be forced to succumb to market pressures and move to the public cloud. With so much important data held by only a few major cloud providers, trust becomes a major issue.

Encryption appears to be the solution to our trust issues; if the providers cannot read the plain-text of our data then surely it is secure? This appears to hold in general, but in the important application of query-based searching, we have a problem: using current methods of homomorphic encryption to perform search over encrypted documents can leak up to 80\% of queries \cite{islam2012access}. Knowledge about the queries made to a data set, along with the amount of documents returned by each query, could lead to some dangerous inferences. As a motivating example, discovering that a query such as $\langle name,~disease\rangle$ made to a medical database returned results would allow an adversary to uncover information about a patients medical status, breaching patient confidentiality.

What allowed the authors of \cite{islam2012access} to infer search queries was knowledge about the documents returned by any specific query. Thus, in order to protect against this kind of attack we need to have some way of preventing the server from knowing which documents it is actually returning in response to any query. Oblivious Random-Access Memory (ORAM) gives us exactly what we want. When using ORAM, not only are two accesses made to exactly the same piece of data computationally indistinguishable to the server, but so too are any two access patterns of the same length.

This project aims to demonstrate that, using a particular ORAM protocol Path ORAM \cite{stefanov2013path}, it is possible to build a system that allows us to search over a set of encrypted documents without leaking the resulting access pattern, protecting the content of the search queries and therefore the confidentiality of the documents.

\section{Challenges}

The first major challenge that faces any security related project is adequately defining the threat model. In order to be able to reason about and evaluate the security properties of the system, we need to know exactly what we assume an adversary to be capable of. Once we have done this we must show that within these capabilities, the security properties that we desire the system to have remain intact. The threat model will be defined in \cref{sec:threatmodel}.

By virtue of being stored in the cloud, we should be able to access our data at any time, from any place, while still maintaining the desired security properties. We also want to be tolerant of network connection errors and client-side crashes. Thus, another challenge is to make the system completely stateless.

In order to make statelessness more efficient, it is necessary to augment ORAM with recursion (\cref{sec:oramintro}), which reduces the amount of transient client-side storage. This enables us to efficiently store the client's state between accesses. Recursion introduces the challenge of choosing how many levels to use. Each extra level of recursion reduces the size of the client's state, but also incurs a time and space overhead. This is explored briefly in \cite{stefanov2013path}, but we will attempt to have the system automatically choose parameters for the recursion based on the size and block size of the underlying storage used by the system.

Finally in order for the system to perform query-based search over encrypted documents we need to implement a file system, an information retrieval module and an encryption module. These modules will be rudimentary, as the main focus of the project is the implementation and optimisation of the ORAM module, but all of them have inherent design and implementation challenges that will be need to be addressed.

\section{Related Work}

ORAM was first introduced by Goldreich et al. in \cite{goldreich1996software}, motivated by the needed for software protection on disks. The model was then expanded and refined for other settings such as secure processors and cloud computing over a number of years (\cite{shi2011oblivious}). \cite{stefanov2013path} had a large impact on the field, mainly due to the simplicity and elegance of the protocol. Since then, lots of work has been done to optimise ORAM constructions (\cite{yu2014enhancing},\cite{ren2015constants}), add additional features (\cite{moataz2015resizable}), and build actual systems based on them (\cite{stefanov2013oblivistore}). An extremely useful thesis, \cite{teeuwen2015evolution}, summarised the entire ORAM field, providing insight into the evolution and therefore future of ORAM.

\chapter{Preparation}

% Describe all work undertaken before the coding - show professional approach to project

% Talk about refining and clarifying model

% Talk about reviewing research papers to find best way of bringing things together

% Talk about choosing OCaml 	for its static typing and powerful module system

% Talk about how this led to designing the system in a modular way (include figure for system)

% Talk about MirageOS and building on top of it

\section{Defining the Threat Model}
\label{sec:threatmodel}

The threat model is defined in terms of a client, a server and an attacker.

\setlength{\unitlength}{0.67mm}
\input{threatModel}
\setlength{\unitlength}{0.5mm}

We assume that the network is under the attacker's control. In the basic model we define the server and the attacker to be passive, and honest, but curious. This means that they will both gather as much information as possible, without deviating from the protocol. Thus the attacker will eavesdrop, but will not prevent messages from arriving at the server, tamper with them in any way or produce their own fake messages. The server will also not tamper with the messages, or with the underlying storage that the protocol is accessing. In this model the attacker is not as interesting as the server, because all communications are encrypted. Thus it is the server, that can see the access patterns of the underlying storage, that we are trying to protect against. The goal of the project is to make sure that this access pattern reveals nothing about the contents of the search queries or the documents in the underlying storage.

We can also extend the model to one where both the attacker and the server become active, freely tampering with messages and introducing new messages, and the server tampers with the underlying storage. In this case we will need to extend our solution with integrity verification.

\section{Introduction to Path ORAM}
\label{sec:oramintro}

Path ORAM is defined in terms of a client and a server, where the client wishes to store data on the server. The data is split into blocks and each block is tagged with a sequence number or address, its position if the data were to be stored sequentially. On the server the data is stored in a binary tree of height $L$, where each node in the tree is a bucket with size $Z$, containing up to $Z$ data blocks. The client requires two local data structures. The stash is a sort of working memory; as data is read from the server it is put into the stash and it is then written back to the server later on. The position map associates with each address a number between $0$ and $2^L-1$, which corresponds to a leaf in the tree. The protocol maintains the invariant that, at anytime, a block with position $x$ in the position map is either in the stash, or in a bucket along the path from the root of the tree to the $x^{th}$ leaf.

This is achieved using \cref{alg:access}, which is split into four main steps:

\begin{description}
	\item[Remap Block] The current position of the block $\mathsf{a}$ is read and then a new position is calculated uniformly at random
	\item[Read Path] The path to the leaf $x$ is read into the stash. At this point the block for address $\mathsf{a}$ is definitely in the stash, if it has ever been written into the ORAM
	\item[Write New Data] If the operation is a $\mathsf{write}$, then the value in the stash is replaced by the new $\mathsf{data^*}$
	\item[Write Path] The path to the leaf $x$ is filled with blocks from the stash. A block with address $\mathsf{a'}$ can be put in the bucket at level $l$, if the path to $\mathsf{position[a']}$ intercepts the path to $x$ at level $l$. If $min(|S'|,Z) < Z$, then the bucket is filled with dummy blocks
\end{description}

Clearly after this, either it was possible to write a block into the stash along the path to its leaf, or not, in which case it is in the stash, and the invariant holds.

\begin{algorithm}[h]
\caption{Read/write data block at address $\mathsf{a}$}
\label{alg:access}
\begin{algorithmic}[1]
    \vskip 10pt
    \Function{Access}{$\mathsf{op,a,data^*}$}
    \vskip 10pt
    \State $x \gets \mathsf{position[a]}$
    \State $\mathsf{position[a]} \gets$ \Call{UniformRandom}{$2^L-1$}
    \vskip 10pt
    \For{$l \in \{0,1,\dots,L\}$}
    	\State $S \gets S~\cup$ \Call{ReadBucket}{$\mathcal{P}(x,l)$}
    \EndFor
    \vskip 10pt
    \State $\mathsf{data} \gets$ Read block $\mathsf{a}$ from $S$
    \If{$\mathsf{op} = \mathsf{write}$}
    	\State $S \gets (S - \{(\mathsf{a,data})\}) \cup \{(\mathsf{a,data^*})\}$
    \EndIf
    \vskip 10pt
    \For{$l \in \{L,L-1,\dots,0\}$}
    	\State $S' \gets \{(\mathsf{a',data'}) \in S : \mathcal{P}(x,l) = \mathcal{P}(\mathsf{position[a']},l)\}$
    	\State $S' \gets$ Select $\min(|S'|,Z)$ blocks from $S'$
    	\State $S \gets S - S'$
    	\State \Call{WriteBucket}{$\mathcal{P}(x,l),S'$}
    \EndFor
    \vskip 10pt
    \State \Return $\mathsf{data}$
    \vskip 10pt
    \EndFunction
    \vskip 10pt
\end{algorithmic}
\end{algorithm}

The security of this operation comes from the fact that positions are assigned uniformly at random. If we consider the sequence of accesses, $$\mathbf{p} = (\mathsf{position}_M[\mathsf{a}_M], \mathsf{position}_{M-1}[\mathsf{a}_{M-1}], \dots, \mathsf{position}_1[\mathsf{a}_1]),$$ any two accesses to the same address will be statistically independent and trivially so will two accesses to different addresses. Thus, by an application of Bayes' rule, $$\Pr(\mathbf{p}) = \prod\limits^{M}_{j=1}\Pr(\mathsf{position}_j[\mathsf{a}_j]) = \left(\frac{1}{2^L}\right)^M$$ and the access pattern is indistinguishable from a random sequence of bit strings.

We might, and for our application will, want to make ORAM stateless, storing all information on the disk, and nothing (except private keys) on the client. We can do this na\"ively by simply dumping all of the state to disk after every operation, but in our current construction, the position map takes $O(n)$ storage space on the client, and the stash $O(\log N)$. Adding recursion to ORAM allows us to reduce the size of the overall client storage to $O(\log N)$, by reducing the space required for the position map to $O(1)$, while maintaining $O(\log N)$ for the stash (actually now multiple stashes). We can now write the client-side storage to the server after each call, and read it back again before the next one, without increasing the asymptotic bandwidth overheads.

Recursion works by storing the position map of our original ORAM, now referred to as ORAM$_0$, in a new ORAM, ORAM$_1$. Now the client stores the position map of this ORAM, plus the stashes of both. If we can store $\chi$ positions in each block of ORAM$_1$, then the new position map is only $O(N/\chi)$. We can then repeat this process until we have the position map of ORAM$_n$ being of constant size. The number of levels required to achieve this are examined in \cite{stefanov2013path} and explored further in \cref{subsec:comparisonWithLiterature}.

\section{Introduction to Inverted Indexes}
\label{sec:invertedindexintro}

The inverted index is the single most important data structure in Information Retrieval. It allows us to perform a large amount of work in advance in order to give performance that is linear in the number of documents involved in a query, much better than a linear scan of all documents that is $O(NK)$, for $N$ documents with an average of $K$ terms. It consists of two parts: the dictionary and the postings. The dictionary is a list, usually stored as a hash table, of all of the terms that appear in a set of documents. Then for each term, we have a postings list, a list of all the documents that contain a term. Collectively these postings lists are referred to as the postings.

So now looking up a single keyword is as simple as hashing the keyword and returning the relevant postings list, if it exists. Simple Boolean operations are also easy to support. Disjunction simply takes the union of two postings lists and conjunction the intersection.

In this project we will restrict operations to simple, space-separated disjunctions, because we are focusing on showing the correctness and efficiency of search using the ORAM implementation, rather than creating an advanced IR system.

Constructing an Inverted Index can be done in three simple steps. We first tokenise the text that we want to add to the index. We then perform some linguistic preprocessing on these tokens, for example stemming, to get them into some sort of normalised form. Finally, we add the document ID of the document to the postings list of each token.

\section{Introduction to MirageOS}

MirageOS is a unikernel operating system designed to run on the Xen hypervisor. The idea is to provide the minimum amount of functionality required of an application by pulling together a number of libraries, and compiling down to an executable that runs directly on the hypervisor. Compared to the traditional approach of running a full operating system such as Ubuntu, with databases, web servers, and the like built on top, the unikernel provides significant speed and memory improvements.

Building the implementation of ORAM on Mirage allows us to have a consistent interface between client machines and cloud providers. We can run the ORAM software on a trusted cloud instance and connect through it from any client machine, to any cloud provider that we like. We also don't need to have the instance running at all times. Mirage is so lightweight, that we could spin up an instance every time we need to perform some actions. This saves us money because, using cloud services like AWS, we only pay for the compute time we actually use. This is the main motivation behind implementing statelessness in the project.

\section{System Architecture}

\setlength{\unitlength}{0.75mm}
\input{mirageStackBody}
\setlength{\unitlength}{0.5mm}

We have discussed a couple of the major building blocks of the implementation, but how does it all fit together? We start with the architecture that we already have, a client and a server, communicating using the servers cloud storage API. Now what we want to do is insert out trusted ORAM instance in between the client and the server. In order to do this with the least hassle to the user, we need to define an API that unifies those of the cloud providers, providing all of the same facilities that the user already has access to. Then we need to have ORAM actually interface with the cloud providers. We can do this by creating modules for each provider that translate their individual API to satisfy MirageOS's BLOCK interface. Actually writing these modules is a fairly trivial exercise, so will be left out of this project.

Now all of the important stuff can happen in between the two interfaces. \Cref{fig:miragestack} shows the overall structure of the ORAM instance. From the bottom up, we have the underlying BLOCK module, which will be the bindings for some cloud provider, or a local block device for the purposes of evaluating this project. Then there is an encryption layer, that will take care of all cryptographic operations in one module, exposing another BLOCK interface. On top of this we have the ORAM layer, which will implement \cref{alg:access}, along with marshalling data into and out of the BLOCK interface on both sides of the operation. We can build a file system at the top layer that takes any BLOCK implementation, which will allow us to perform tests of the overhead introduced by different combinations of modules. Then we will add our search module along side the file system, which will construct and store the inverted index that we described in \cref{sec:invertedindexintro}, as well as exposing search operations to the client. Combining all of these modules will give a complete system, capable of performing secure search over encrypted documents.

\section{Requirements Analysis}

% Do requirements analysis in order to show that I thought about all of these things

\begin{description}
	\item [High Priority] Basic ORAM implementation
	\item [Medium Priority] File System
	\item [Medium Priority] Search Module
	\item [Low Priority] Encryption
	\item [Low Priority] Further Optimisations including Recursion and Statelessness
	\item [Low Priority] Integrity Verification (Extension)
\end{description}

ORAM forms the basis for the whole project and as such is given high priority. Once the basic ORAM is completed, adding a file system and search module gives us a complete system that we can evaluate, so these two modules are of medium priority. Encryption and further optimisations will round of the project, but are not necessary in order to get something that we are able to evaluate, so are given low priority. Finally, integrity verification is left as an extension, and therefore has low priority.

\section{Choice of Tools}

\subsection{OCaml}

Having decided to build ORAM on top of MirageOS, OCaml was really the only choice of programming language, because Mirage applications and libraries are all built in OCaml. However, OCaml was also part of the reason for choosing to build on Mirage.

OCaml has an extremely powerful module system, making it easy to parameterise the ORAM implementation over module signatures for Block devices or other system components. This not only encourages more generalised programming, but also allows powerful techniques like recursive modules to be exploited. For instance, to implement recursive ORAM, the position map of the main ORAM is another ORAM, so we can simply parameterise over a position map signature and pass the ORAM implementation to itself as the position map.

OCaml's static typing system is also indispensable for ensuring correctness of programs and increasing productivity.

\subsection{Libraries}
\label{subsec:libraries}

The libraries used for building ORAM are listed in \cref{tab:libraries}.

\begin{table}[h]
\centering
\begin{tabularx}{\textwidth}{|l|l|X|l|}
\hline
\textit{Library} & \textit{Version} & \textit{Purpose} & \textit{License} \\
\hline \hline
Mirage & 2.6.1 & System Component Interface Definitions, Application Configuration Framework & ISC \\
\hline
Jane Street's Core & 113.00.00 & Data Structures, Algorithms & Apache-2.0 \\
\hline
LWT & 2.5.1 & Threading & LGPL-2.1 \\
\hline
Cstruct & 1.8.0 & Data Structure & ISC \\
\hline
Alcotest & 0.4.6 & Unit Testing & ISC \\
\hline
Mirage Block CCM & 1.0.0 & Encryption & ISC \\
\hline
Stemmer & 0.2 & Linguistic Processing & GNUv2 \\
\hline
\end{tabularx}
\caption{Libraries used by Mirage ORAM}
\label{tab:libraries}
\end{table}

\subsection{Development Environment}

Good tooling is essential to productivity when building large projects. For OCaml, one of the most important tools is OASIS, which automatically generates Makefiles for a project, based on a specification file. Using the OCaml compilers directly quickly gets infeasible, but OASIS takes care of everything for you. Emacs also proved to be an incredibly useful tool, because there are a number of OCaml specific plugins that provide everything from code indenting and syntax highlighting, to autocompletion and type inspection. It is also possible to run a shell from within Emacs itself, where it is possible to interpret, compile, and run the code, which gives a big boost to productivity.

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textit{Tool} & \textit{Version} & \textit{Purpose} & \textit{License} \\
\hline \hline
Mac OSX & 10.11.2 & Operating System & Proprietary \\
\hline
Emacs & 24.5 & Text Editor & GPL \\
\hline
OPAM & 1.2.2 & Package Manager & GPLv3 \\
\hline
OASIS & 0.4.5 & Build Tool & LGPL-2.1 \\
\hline
\end{tabular}
\caption{Tools used in the development of Mirage ORAM}
\label{tab:devtools}
\end{table}

% Do a table of tools used including OPAM, OASIS, git, Make, Atom, etc.

\section{Software Engineering Techniques}

% Talk about writing interface files before writing code in order to fit code to requirements and designing before implementing

% Talk about the ability to do Test Driven Development and the power of unit tests

I employed two major techniques to ensure my code was well thought through and well built, while remaining productive.

First of all a Test Driven Development approach allowed me to fail fast. I wrote unit tests for each new piece of code that was written, until I was sure that it was working correctly. This meant that when it came to combining small modules into a larger system, things worked together as expected more often than not.

Secondly, I wrote interface files before writing the actual implementation. This meant that I had to think about the design of each module thoroughly before writing any code and also meant that I could make adjustments to other modules in order to fit with the new design.

Combining these techniques with documentation and structuring of both the source code and the source repository, led to a manageable and feasible development workflow.

\section{Summary}

In this chapter I have discussed the work that was undertaken before development began. This included a rigorous definition of the threat model, a brief introduction to the major algorithms, data structures and libraries, an overview of preliminary architectural designs, and a discussion of the techniques and tools used in the development process.

The next chapter will show how all of this information was used to achieve the aims of the project.

\chapter{Implementation}

This chapter describes the process that took the designs and algorithms of the previous chapter and turned them into a functioning system. As it is the core of the project, the implementation of Path ORAM is discussed first (\cref{sec:pathORAM}), followed by the file system (\cref{sec:fileSystem}), the search module (\cref{sec:searchmodule}) and finally encryption (\cref{sec:encryption}).

% Describe what was actually implemented

\section{Path ORAM}
\label{sec:pathORAM}

The structure of Path ORAM is described abstractly in \cref{sec:oramintro}, in terms of the core data structures and the access algorithm. In this section we discuss how those data structures were realised and the design decisions involved in the implementation.

\subsection{Inherent Constraints}
\label{subsec:constraints}

By virtue of writing an implementation to satisfy an existing module signature, there are a number of constraints put on the design of our system.

The first major constraint is the use of the Cstruct library, discussed in \cref{subsec:libraries}. The underlying block device requires a buffer of type \texttt{Cstruct.t} to read to/write from and in order to satisfy the \texttt{BLOCK} module signature, ORAM needs to return data as a \texttt{Cstruct.t}. Thus, to avoid unnecessary conversions, we will pass our data around in this form.

Another constraint is the usage of \texttt{int64} as the type of addresses in \texttt{BLOCK}'s, \texttt{read} and \texttt{write} operations. Again, to avoid unnecessary (and potentially unsafe) work converting between types, we will use \texttt{int64}s wherever necessary.

\subsection{Stash}

The stash stores blocks of data temporarily before they are written back into ORAM. It needs to support operations of insertion, lookup based on address and removal. For this job I chose an \texttt{int64}-keyed hash table from Jane Street's Core library, with \texttt{Cstruct.t} values. This was put into its own module, abstracting away the underlying type, meaning that we could swap implementations of the Stash module without breaking the core code of the ORAM module.

The hash table gives us constant time for the operations of insertion, lookup and removal, making it ideal for our needs. The hash table implementation takes an initial size as a parameter, and expands when necessary. This would add a large overhead, because we would have to copy the entire contents of the stash. However, as shown in \cite{stefanov2013path}, we require exactly $Z\log_2N$ transient storage, where $N$ is the size of the ORAM in blocks, and on top of that, we require a constant amount of space for persistent stash storage. \Cref{tab:stashsizes} shows the maximum stash size required depending on the security parameter, $\lambda$, and the bucket size $Z$. A stash with security parameter $\lambda$ has probability $2^{-\lambda}$ of exceeding this stash size.

In order to achieve statelessness, we need to be able to write the stash to disk, so there is going to be a trade-off between maximum stash size and security parameter. A larger maximum stash size increases bandwidth, but a security parameter set too low will not allow us to allocate the storage space for the stash in advance. For the purposes of this project, we will parameterise in both bucket size and security parameter, allowing us to discover empirically the values that optimise the construction.

\begin{table}
\centering
\begin{tabular}{|l|l|l|l|}
	\hline
	& \multicolumn{3}{c|}{Bucket Size ($Z$)} \\
	\cline{2-4}
	Security Parameter ($\lambda$) & 4 & 5 & 6 \\
	\cline{2-4}
	& \multicolumn{3}{c|}{Max Stash Size} \\
	\hline
	80 & 89 & 63 & 53 \\
	\hline
	128 & 147 & 105 & 89 \\
	\hline
	256 & 303 & 218 & 186 \\
	\hline
\end{tabular}
\caption{Empirical results for maximum persistent stash size from \cite{stefanov2013path}}
\label{tab:stashsizes}
\end{table}

\subsection{Position Map}

The position map associates a leaf position with each address of the data. As mentioned in \cref{subsec:constraints}, we are constrained to using \texttt{int64} addresses, thus we need to be able to support a position map that is indexed by 64-bit integers. OCaml provides us with a Bigarray module, but the size of these arrays is specified using the OCaml \texttt{int} type. This type actually uses only 63 bits on a 64-bit machine and 31 on a 32-bit machine. Both of these types are also signed, so we need to represent a type that can range up to $2^{63} - 1$, using a type that can only go up to $2^{30} - 1$ on a 32-bit machine.

In order to do this we need to use 3-dimensional arrays. We take an \texttt{int64} value and split its bits into a 4-bit value and 2 30-bit values. The 4-bit value is the most significant bits, and will therefore be 0 unless we store more than $2^{60}$ blocks. The 30-bit values are guaranteed to be converted into positive \texttt{int}s, which we can then use to address two dimensions of the array. We have to perform some input sanitation to make sure that the 4-bit value (and therefore the 64-bit value) is positive.

Now the only remaining problem is creating the position map. \Cref{alg:posmapdims} shows how we translate from a desired \texttt{int64} size to the dimensions of a three dimensional array. After splitting the \texttt{int64} as described above, we must add one to the first two dimensions, because we always want them to be at least of size 1. If a higher dimension is greater than 1, then all lower dimensions become their maximum value, in this case $2^{30}-1$. We can now create an array using these values that is guaranteed to be at least the size that we require on both 32-bit and 64-bit machines.

\begin{algorithm}
\caption{Calculate the dimensions of a 3D array given total desired size}
\label{alg:posmapdims}
\begin{algorithmic}[1]
\vskip 10pt
\Require{$\mathsf{size} > 0$}
\vskip 10pt
\Function{PosMapDims}{$\mathsf{size}$}
\vskip 10pt
	\State $(x, y, z) \gets$ \Call{SplitIndices}{$\mathsf{size}$}
\vskip 10pt
	\State $x \gets x + 1$
	\State $y \gets y + 1$
\vskip 10pt
	\If{$x > 1$}
		\State $y \gets \mathsf{0x3FFFFFFF}$
		\State $z \gets \mathsf{0x3FFFFFFF}$
	\ElsIf{$y > 1$}
		\State $z \gets \mathsf{0x3FFFFFFF}$
	\EndIf
\vskip 10pt
	\State \Return $(x,y,z)$
\vskip 10pt
\EndFunction
\vskip 10pt
\end{algorithmic}
\end{algorithm}

\subsection{Creating ORAM}

We want ORAM to be able to replace any existing block device in any Mirage program. In order to do this we need access to the methods of the underlying block device as well as the block device itself. Thus, we need to build an ORAM functor, that takes a module satisfying the \texttt{BLOCK} interface, shown in \cref{lst:blocksig}, and gives us a new module satisfying the same interface.

In order to get access to this underlying device, we need a \texttt{create} method, which takes a block device as input and returns something of type \texttt{Oram.Make(B).t}, shown in \cref{lst:orammaketype}. This type contains the ORAM parameters such as \texttt{bucketSize} and \texttt{offset}, structural information such as the \texttt{height} of the ORAM and the \texttt{numLeaves}, and pointers to the stash, position map, and underlying block device.

The following parameters are passed as input to the \texttt{create} method, along with the block device:

\begin{description}
  \item[\texttt{size}] The desired size of the ORAM in blocks
  \item[\texttt{blockSize}] The desired size of a single block in bytes
  \item[\texttt{bucketSize}] The number of blocks in a bucket
\end{description}

Using these, the \texttt{create} method can calculate new structural information. First we need to calculate the number of sectors required for a block as $$\mathtt{sectorsPerBlock} = \frac{\mathtt{blockSize} - 1}{\mathtt{sector\_size}} + 1,$$ which rounds up the number of sectors so we can always fit the desired block size. Next, we calculate the sector size of the ORAM as $$\mathtt{sector\_size} = \mathtt{sector\_size} \times \mathtt{sectorsPerBlock} - 8,$$ which is the block size, minus 8 bytes for the address, which needs to be stored along with the data. Now we can calculate the height of the ORAM, but we need to consider two cases. If the desired size of the ORAM is specified, then we simply calculate the height as $$\mathtt{height} = \left\lfloor \log_2\left(\frac{\mathtt{size}}{\mathtt{bucketSize}} + 1\right)\right\rfloor - 1.$$ This comes from rearranging the equation for the size of the binary tree, $2^{\mathtt{height} + 1} - 1$, introducing the floor operator so that the resulting binary tree is less than or equal to the desired size. If the size is unspecified, we assume that we should fill as much of the device as possible, so we calculate $$\mathtt{size} = \frac{\mathtt{size\_sectors}}{\mathtt{sectorsPerBlock}}$$ and then perform the same calculation as above with this new value. Finally we calculate, \texttt{numLeaves} and a new value for \texttt{size\_sectors} trivially.

This is all of the structural information we require, so now we only have a couple of things left to do. We must create instances of the client-side data structures and we must initialise the ORAM space. The first simply calls the creation functions of the associated data structures. The second loops through the block device, writing dummy blocks to every location. Dummy blocks have address -1, and are ignored by the access protocol. Now we can return everything that we have as an instance of \texttt{ORAM.Make(B).t}.

\begin{listing}[h]
\caption{The type of an ORAM device \texttt{ORAM.Make(B).t}}
\label{lst:orammaketype}
\inputminted[firstline=27, lastline=58]{ocaml}{../mirage-oram/lib/oram.ml}
\end{listing}


\begin{listing}
\caption{Mirage BLOCK module signature}
\label{lst:blocksig}
\vskip 10pt
\begin{minted}[breaklines]{ocaml}
module type BLOCK = sig

  type page_aligned_buffer = Cstruct.t

  type +'a io = 'a Lwt.t

  type t

  type error = [
    | `Unknown of string (** an undiagnosed error *)
    | `Unimplemented     (** operation not yet implemented in the code *)
    | `Is_read_only      (** you cannot write to a read/only instance *)
    | `Disconnected      (** the device has been previously disconnected *)
  ]

  type id

  val disconnect: t -> unit io

  type info = {
    read_write: bool;    (** True if we can write, false if read/only *)
    sector_size: int;    (** Octets per sector *)
    size_sectors: int64; (** Total sectors per device *)
  }

  val get_info: t -> info io

  val read: t -> int64 -> page_aligned_buffer list -> [ `Error of error | `Ok of unit ] io

  val write: t -> int64 -> page_aligned_buffer list -> [ `Error of error | `Ok of unit ] io

end
\end{minted}
\end{listing}

\subsection{Accessing ORAM}

Now that we have the client-side data structures and our ORAM module, we can almost implement \cref{alg:access}. Before we can though, we need the surrounding plumbing. The \texttt{BLOCK} interface functions \texttt{read} and \texttt{write} input/output data as a list of \texttt{Cstruct.t}s, so they must split this into chunks before calling \texttt{access} on each one. On the other side of access, we need the subroutines \textsc{ReadBucket} and \textsc{WriteBucket}, which access the underlying block storage.

It is the second two of these plumbing functions that have a much more interesting role. They are actually responsible for maintaining the logical binary tree structure. There are no physical pointers, but instead the structure is built purely through calculating the appropriate address of a bucket. The bucket on the path to leaf $x$ at level $l$ is calculated using \cref{alg:bucketaddress}.

\begin{algorithm}[H]
  \begin{algorithmic}
  \vskip 10pt
    \Function{BucketAddress}{$x$,$l$}
      \State $address \gets 0$
      \For{$i = 0;~i < l;~i++$}
        \If{$x >> (i + \mathtt{height} - l)~\&\&~1 = 1$}
          \State $address \gets (2 \times address) + (\mathtt{bucketSize} \times \mathtt{sectorsPerBlock} \times 2)$
        \Else
          \State $address \gets (2 \times address) + (\mathtt{bucketSize} \times \mathtt{sectorsPerBlock})$
        \EndIf
      \EndFor
      \State \Return $address$
    \EndFunction
  \vskip 10pt
  \end{algorithmic}
  \caption{Calculating the address of the bucket at level $l$ on the path to leaf $x$}
  \label{alg:bucketaddress}
\end{algorithm}

This is most easily explained using \cref{fig:bucketaddress}. Here we can see the nodes labelled in order of their position in memory. The leaves are also labelled, but the binary representations of these labels are actually more important. The binary representation, read from left to right, tells us how to reach the leaf. To get to leaf 5, with binary representation 101, we go right, left, right. When we go left, we double the label on the node and add one, and when we go right, we add two. Multiplying this node label by the block size and the bucket size gives us the physical address of the node. So for a node at level $l$, we only compare the first $l$ bits, following the procedure above.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[level/.style={sibling distance=75mm/#1},
        level 3/.style={sibling distance=18mm},
        every node/.style={minimum size=10mm,shape=circle},
        edge from parent/.style={draw,-latex}]
        \node[draw,grow=down] {0} 
        child {
          node[draw] {1}
          child { node[draw] {3}
            child {
              node[draw] (n7) {7}
            }
            child { node[draw] (n8) {8} }
          }
          child { node[draw] {4} 
            child { node[draw] (n9) {9} }
            child { node[draw] (n10) {10} }
          }
        }
        child {
          node[draw] {2}
          child { node[draw] {5}
            child { node[draw] (n11) {11} }
            child {
              node[draw] (n12) {12}
              edge from parent node[near start,right] {1}
            }
            edge from parent node[near start,left] {0}
          }
          child { node[draw] {6} 
            child { node[draw] (n13) {13} }
            child { node[draw] (n14) {14} }
          }
          edge from parent node[above] {1}
        };
        \node [below of=n7] {0};
        \node [below of=n8] {1};
        \node [below of=n9] {2};
        \node [below of=n10] {3};
        \node [below of=n11] {4};
        \node [below of=n12] {5};
        \node [below of=n13] {6};
        \node [below of=n14] {7};
  \end{tikzpicture}
  \caption{Visualisation of \cref{alg:bucketaddress}}
  \label{fig:bucketaddress}
\end{figure}

So we can now input/output data from the outside and the underlying block device. This leaves most of \cref{alg:access} fairly trivial to implement. Remapping the blocks requires a simple call to a pseudo-random function, reading in the path just adds the contents of each bucket to the stash, and writing new data is as simple as setting a value in the stash. The only interesting part left is lines 11-16. This is where we decide which blocks should be put into the path.

The naive implementation of this, and that suggested by \cref{alg:access}, loops through the stash and finds blocks such that the bucket at level $l$ on the path to leaf $\mathsf{position[a']}$ is the same as the bucket at level $l$ on the path to leaf $x$. There are two small optimisations we can make here. The first is to perform the position lookup only once, attaching positions to the blocks in a temporary data structure, avoiding repeated work at each level. The second avoids calculating the bucket addresses entirely. We can do this by noting that in order for the paths to two leaves to intersect at level $l$, the leaves must have the same first $l$ bits. Thus, we can simply perform a right bit shift on both $x$ and $\mathsf{position[a']}$ of $\mathtt{height} - l$ bits, and check for equality.

So at this point we have a functioning ORAM functor, that can be used to augment a block device in any Mirage program. In \cref{subsec:recursion,subsec:statelessness,subsec:oramoptimisation} we look at optimisations and extensions to this ORAM construction, before moving onto to the further aims of the project.

%\begin{listing}[h]
%	\caption{Implementation of \cref{alg:access}}
%	\label{lst:access}
%	\inputminted[firstline=183, lastline=207]{ocaml}{../src/oram.ml}
%\end{listing}

\subsection{Recursion}
\label{subsec:recursion}

The essence of recursive ORAM, is that the position map of one ORAM is another ORAM. Thus, we can extend our original ORAM functor, parameterising it in the implementation of the position map. To do this we use a single interface, that is satisfied by both the in memory position map and the ORAM module. We can apply this new ORAM functor with the in memory position map module to get our original construction. However, we can now take this further, applying the functor again with the result of the first application, and this can be done to an arbitrary depth. Recursion has been made easy using the power of OCaml's module system.

There is of course hidden complexity here. How do we create a recursive ORAM? We definitely can't assume that the data ORAM can use the whole of the disk anymore, so we will have to do some calculations. How do we initialise recursive ORAM? How do we actually use ORAM as a position map? We will examine all of these now.

\mytodo{In particular talk about/show maths involved in automatically determining optimal size/number of levels of recursion}

% Talk about wanting to have automatic recursion, and the constraints of the type system

\subsection{Statelessness}
\label{subsec:statelessness}

In order to achieve statelessness for ORAM, we need to store a few different things. We need to store type information, the stash, and the position map. We will first talk about how to layout all of this information on disk, before moving on to talk about how we actually get it there.

Once we have initialised ORAM and begun to use it, we do not want to move it around on disk, because we would have to copy the entire thing. We do however need to store the information necessary to discover ORAMs existence in a well-known location, in order to allow us to reconnect to it. This leads us to storing a superblock in the first sector of the block device. This block will contain a pointer to the location of the rest of the state, along with its length. This way, we can store ORAM starting at the second location on disk, and then append all of the state at the end of the ORAM section, meaning we will never have to move ORAM once we have initialised it.

Now we actually need to store the state, which means we need some method of serialising it, ready to be written to disk. We could implement this manually, but for the majority of the information we can take advantage of an existing serialisation library, Jane Street's Bin\_prot. This is a binary protocol, that allows you to annotate a type with \texttt{[@@ deriving bin\_io]} and will then generate functions to read and write instances of the type into buffers. We are able to use this for all of the type information for ORAM, as well as for the stash. This leads us to splitting the ORAM type into a core, that can use Bin\_prot, and an extended type, that includes the position map and the underlying block device. This structure is shown in \cref{lst:orammaketype}.

The position map is more difficult to serialise, because under recursive ORAM, it might actually be another ORAM. We obviously don't want to write the entire of the position map ORAM onto the disk a second time, so we need a custom serialisation function for the position map that will store only meta-data for ORAM position maps, and will store the entire position map in the base case. We want to store all state right at the end of the block device, after all recursive instances, so this function actually collects the data from all the levels of recursion together into one buffer.

Now that we can write all of the major parts into the buffer, we simply collect everything together and dump it at the end of the block device. After this is done, we are able to disconnect from ORAM safely. Reconnecting to ORAM is now a case of checking for the presence of the superblock, reading in the location and length of the state, reading the actual state, and then calling the connect function on the position map. The connect function allows each recursive ORAM instance to have its own reference to the underlying block device, but does nothing in the case of the in memory position map.

\section{File System}
\label{sec:fileSystem}

In order to perform search over documents, we need some way of actually storing those documents. This section describes the design and implementation of a basic file system that satisfies the requirements of the project.

\subsection{General Design}

The most common way of building a file system on top of a block device is through the use of inodes. An inode contains meta-information about a file along with pointers to the actual data blocks. For the purposes of this project, an inode will simply be one sector of the block device, containing the length of the file, followed by the list of pointers. In a system with more complex needs the inode would contain more information, such as modification/access timestamps, file permissions, etc., but we simply want to be able to read and write documents.

We need to be able to access the inode for a particular file quickly, so we should store its location in an index. We could perform lookup based on the actual filename, but the names have variable lengths, therefore, because we want to store the index, it is better to lookup based on the hash of the filename. \Cref{subsec:inodeindex} describes the implementation of the Inode Index.

We also need to allocate space on the block device for inode index blocks, for inode blocks and for data blocks. So we need a map that tells us which blocks on the device are free and allows us to update it as new blocks are needed. \Cref{subsec:freemap} describes the implementation of the Free Map.

We could now build a working file system, but we want it to be stateless. In order to do that, we need to store enough information to be able to reconstruct its in-memory representation. All we actually need to store is the root address of the Inode Index and the length of the Free Map. These two alone allow us to locate the data structures on disk when reconnecting to the block device. We store these two pieces of information at address 0 in what we call the Superblock.

\subsection{The Inode Index}
\label{subsec:inodeindex}

We need a data structure that associates keys, in the form of file hashes, with values, in the form of pointers to inodes. We want to support operations of insertion, lookup and deletion efficiently, but we also want to store the data structure on disk. This leads us naturally to an implementation using B-Trees.\footnote{The algorithms for B-Tree operations were adapted from \cite{CLRS09}}

B-Trees are a generalisation of self-balancing binary search trees, where each node can have more than one child. If a node has $n$ children, then it stores $n-1$ keys. It is guaranteed that $$ \forall k \in child_m, j \in child_{m+1} . k < key_m < j, $$ that is, a key is greater than all the keys to its left and less than all the keys to its right.

B-Trees are an efficient on-disk data structure, because we can use the whole of a disk sector for one node. This gives us an extremely high branching factor, reducing the depth of the tree and therefore the number of disk sectors that we need to access in any single operation. On creation of the file system, we calculate the branching factor of the tree in order to fill as much of each sector as possible with useful information.

\subsection{The Free Map}
\label{subsec:freemap}

In order to allocate space efficiently, we can simply use an array of bits the size of the block device. We again want to have an on-disk data structure, or at least one that can easily be flushed to disk regularly. It was therefore beneficial to write my own bit array based on \texttt{Cstruct}s, rather than using a library implementation. This gives us the ability to write the whole structure directly onto the disk using the block device methods, without any cumbersome translation.

The \texttt{Cstruct} library performs data access in bytes. This leads us to \cref{alg:bitgetset} for getting and setting individual bits. To get the $n^{th}$ bit, we must get the $\frac{n}{8}^{th}$ byte and extract it from there. To do this, we calculate the index of the bit in the byte, shift a 1 to that position, and perform an and, masking that bit. Setting is a similar operation, but seeks to preserve the surrounding bits. To set a 1, we calculate the index of the bit in the byte, shift a 1 to that position, and perform an or, preserving all other bits. Setting a 0 is slightly trickier. We want to perform an and with a bit string that is 0 at the desired position and 1 everywhere else, but shifting fills empty bits with 0s. We can however use De Morgan's Law $$ a~\&\&~b = \neg (\neg a~||~\neg b) $$ to convert this to an operation involving a bit string that has a 1 at the desired position and 0s everywhere else.

\begin{algorithm}[H]
\caption{Getting and setting individual bits in a byte array}
\label{alg:bitgetset}
\begin{algorithmic}
\vskip 10pt
\Function{GetBit}{$\mathsf{index}$}
  \State $byte \gets \mathsf{byteArray[index]}$
  \State $shift \gets 7 - \mathsf{index} \bmod 8$
  \State \Return $byte >> shift~\&\&~1$
\EndFunction
\vskip 10pt
\Function{SetBit}{$\mathsf{index,boolean}$}
  \State $byte \gets \mathsf{byteArray[index]}$
  \State $shift \gets 7 - \mathsf{index} \bmod 8$
  \If{$\mathsf{boolean}$}
    \State $byte \gets byte~||~1 << shift$
  \Else
    \State $byte \gets \neg (\neg byte~||~1 << shift)$
  \EndIf
  \State $\mathsf{byteArray[index]} \gets byte$
\EndFunction
\vskip 10pt
\end{algorithmic}
\end{algorithm}

\section{Search Module}
\label{sec:searchmodule}

So we have our documents and we can access them without revealing which ones we are accessing. Now the final piece of the puzzle is actually performing search. We discuss building an Inverted Index, the data structure that will allow us to search efficiently, in \cref{subsec:invertedindex}. We then discuss the front-end of the whole application, the search API, in \cref{subsec:searchapi}.

\subsection{Inverted Index}
\label{subsec:invertedindex}

The basics of Inverted Indexes are discussed in \cref{sec:invertedindexintro}. As stated there, the Index consists of two main structures, the dictionary and the postings. For the dictionary, we will do the usual thing, which is to implement it as a hash table. This provides us with $O(1)$ lookup and insertion, which are the main operations we will be performing. The postings are more flexible. In our implementation we want to store the file names, because they are not actually stored in the filesystem itself. We also want to perform intersection of postings lists, allowing us to perform phrase search. Thus, we will use a Hash Set, a data structure built on top of a hash table, that stores a set of keys, and has the added benefit of keeping them unique for us.

Having decided on our data structure, we need to actually index files. As usual in this project, the files will be \texttt{Cstruct}s. So we have a number of steps to perform in order to process a file. We first convert the file to a string and immediately strip it of characters we don't need, pretty much all punctuation. At this point we have a sequence of alphanumeric character strings, separated by spaces and newlines, so we can perform a split on these characters to get a list of words.

We could perform indexing now, adding the name of the current file to the postings list of every word in our list, but there are a couple of things that we want to do first. We really don't want to store separate words for `run', `ran', `runs', and so on, so we will perform some linguistic preprocessing, stemming the words using Porter's stemming algorithm. I used a small open-source library implementation of this algorithm. This technique not only reduces the size of the index, but also arguably improves search, because now queries for `run' can automatically returns documents containing any morphological derivation.

Finally, we remove duplicates from our list of words, reducing insertion overhead, and put the entries into the index.

For our purposes we will only implement simple conjunctive phrase search, meaning we look for documents containing all of the words in a space separated query string. Now search is as simple as performing the same preprocessing on the query string, performing lookup on each of the queries in turn and taking the big intersection of the resulting list of hash sets. In order to make this intersection operation efficient, we sort the list by order of hash set size. Then we can filter the smaller hash set by checking for membership in the larger hash set. This means we perform one constant time lookup for each member of the small set, rather than the large, giving a large performance boost, as this smaller set is monotonically decreasing.

\subsection{Keyword Search API}
\label{subsec:searchapi}

The final step in an end-to-end system is the API. We need to wrap file system access, indexing and search all into one module that provides a single point of entry for an encrypted search system.

We have three main operations that are the most important to support. Writing files, reading files, and searching over files. We will not be concerned with deleting files at the moment, but it is left as an extension if time permits.

Writing files is the most important step, because this is where the search module does the indexing. On write, we first write through to the first system, then index the file and finally flush the index to disk to make sure it persists. Reading files is simply a pass through to the file system and search makes calls to inverted index.

\section{Encryption}
\label{sec:encryption}

Encryption is something that it can be fatal to get wrong. In the case of ORAM, if you don't have encryption, it's completely superfluous. Thus, we want to use tested and trusted cryptographic libraries, rather than rolling our own. Luckily for us, there is an existing implementation of an encrypted block device satisfying Mirage's \texttt{BLOCK} interface, that provides a functor very similar to the ones that we created for ORAM. We simply have to chain together the application of this functor with the ones that we are already using to get an encrypted block device.

\section{Summary}
\label{sec:implSummary}

In this chapter we have discussed the implementation of all of the components of our system, including the important design decisions and trade-offs that were made. We have seen how to implement recursive Path ORAM in a way that allows it to plug into existing MirageOS programs, and we have seen how to build a file system and search operations on top of it.

We now move on to the important task of evaluation, where we make sure that I have implemented ORAM in a way that ensures functionality, performance, and security, and have therefore achieved the aims of the project.

\chapter{Evaluation}

% ### Functionality ###

% Show that the unit tests show that individual components do what they are specified to do

% Path ORAM reads in and out correctly

% Encryption does make things encrypted

% Search is sound and complete...

% Etc.

% Use QuickCheck to build randomised testing

% ### Performance ###

% Evaluate the performance of the code and do it with different configurations, varying functors used, size of input, potentially simulated network latency etc.

% ### Security ###

% Use statistical methods to show that access pattern is easily visible to Bob before applying ORAM to the system and the show statistical evidence the access pattern is hidden after applying ORAM

% Show specifically that with the entire access pattern, the server can infer which documents are returned by each query, and could therefore perform the attack described by Islam et al.

This chapter explains the methodology used to ensure the correctness of the ORAM implementation, as well as analysing its performance and security properties. \Cref{sec:overallResults} gives a summary of the results and compares them with expectations. \Cref{sec:unitTests} discusses functional testing through the use of Unit Testing and Randomised Testing. \Cref{sec:performanceTesting} then goes on to discuss performance, and then finally we analyse the security of ORAM in \cref{sec:securityAnalysis}.

\section{Overall Results}
\label{sec:overallResults}

Overall, ORAM performed as expected in terms of functionality, performance, and security. It operated correctly, writing files and reading the same data back out. It continued to do so with the additions of statelessness, recursion, and encryption, so all parts of the system were functional separately and as a whole. In terms of performance, my implementation agreed with the theoretical bounds given in \cite{stefanov2013path}, which state $O(\log N)$ time overhead, $O(\log N)$ client-side storage in the non-recursive case, and $O(1)$ client-side storage in the recursive case. The value of the constant in the last instance was given based on empirical results, and my result (dis)agreed with this, how? Finally, the security analysis showed that ORAM did indeed have a statistically random access pattern, ensuring the security of the implementation.

\mytodo{Tweak this based on actual results}

\section{Unit Tests}
\label{sec:unitTests}

Unit testing was used throughout the development process, which allowed me to be sure that individual components were functioning correctly, before I combined them into larger more complicated systems. This section describes the most important test cases that were examined for each module and discusses the use of randomised testing to cover a larger range of input values. Code coverage testing was also used to make sure that the tests were visiting all parts of the system.

\subsection{Stash}

There three main cases to test for the stash:

\begin{itemize}
  \item Values not expected to be in the stash are not found
  \item Values that have been added to the stash are found
  \item Adding dummy blocks to the stash has no effect
\end{itemize}

During the development process, I simply hand-coded a small number of example cases, but in order to test more extensively, I coded the above three cases as properties for randomised testing. This generates a number of test cases and verifies that the properties hold in every case and allows us to cover far more cases than hand-coded tests alone.

\subsection{Position Map}

We need to test the two main aspect of the position map. Firstly, the translation of 64 bit addresses into 3 regular integers, and then its actually operation as a data structure.

The code performing the translation is essentially a mathematical definition in itself, so any property definition that we might use for randomised testing would probably just be the original code. Thus, in this instance we simply check a few hand chosen random cases, along with the important edge cases. The edge cases we want to check are the maximum, and minimum values, along with values either side of a change in the higher indices, that is values with output $(x,y,max\_int)$ and $(x,y+1,0)$, and similarly for the higher index.

In terms of operation, we want to check that on adding a value to the position map, we read back the same value, and that trying to add a value at an address outside of the allowed range results in an error. Both of these cases can be coded up as properties for randomised testing.

\subsection{ORAM}

The ORAM implementation is particularly amenable to randomised testing, because we tend to define inverse functions for most of its functionality. This makes it very easy to write properties for randomised testing of the form $f(f^{-1}(x)) = x$. This allows us to check that each stage of ORAM is operating correctly, from writing individual blocks, through writing entire paths, to writing entire files.

For other functions that were not so easy to code properties for, regular unit testing was used. These include reconnecting to ORAM to test statelessness, and performing simple calculations, such as computing the height for ORAM.

\subsection{FreeMap}

The FreeMap allocates blocks in the block device to be used by different parts of the file system. We need to make sure that on creation, it allocates the correct number of initial blocks, and then subsequently always allocates the correct number of blocks, if they are available, and only ever allocates blocks that are actually free.

During development, I used only a handful of test cases, covering some of the most important edge cases. This included creating the map, and checking that nothing was allocated to begin with except the first $n$, where $n$ is passed into the creation function. Then, I checked that allocating and deallocating a few different sequences of blocks led to the expected results. Finally, I checked that if there were not enough free blocks, that an error was returned.

After main development had finished, I added some randomised testing to this module to cover a wider range of inputs.

\subsection{BTrees}

It is not possible to test the B-Tree library directly, because it only gives us a functor to create a B-Tree. Thus the B-Tree was tested using the Inode Index, the canonical use case of the library in this system. In order to test the B-Tree properly, it was necessary to use randomised testing to create a reasonable access pattern that was guaranteed to cause splitting of the root node.

\subsection{Inodes}

The inodes needed to be tested to make sure they could add and delete pointers, while maintaining a correct count. This is again amenable to randomised testing, although unit tests were also used throughout the development to test specific cases that would be expected to cause exceptions.

\subsection{File System}

In order to test the file system I created a large number of random files and used randomised testing to ensure that under any access pattern the correct files were always read back out once they had been written in. This also included testing to ensure that reasonable exceptions were produced when the file system became full, or a file did not exist in the system.

\subsection{Search Module}

The search module was tested for correctness, i.e. if a file containing a word had been put into the system, then it would appear in the search results. This was difficult to randomise, so I manually constructed a number of test scenarios.

\section{Performance Testing}
\label{sec:performanceTesting}

\subsection{Parameter Optimisation}
\label{sub:parameterOptimisation}

Before performing the main experiments, I decided to optimise the parameters of ORAM, in order to allow the experiments to run faster. The main parameter in question is the block size, which has been shown in \cite{ousterhout1985trace} to dramatically affect the speed of IO operations. I discovered that this was indeed the case with ORAM, as can be seen in \cref{fig:blockSizePlot}. It appeared that increasing the block size has an unbounded increase on performance, but I settled with a block size of 1MB to trade-off between speed and the possibility to specify the size the block device.

\subsection{Comparison with Literature}
\label{subsec:comparisonWithLiterature}

In order to effectively test the overhead due to ORAM, two things needed to be done very carefully. The first was isolating and removing major sources of uncertainty. When I first ran the experiments, I attempted to run them on my local machine. In this environment, other processes interfered with the ORAM process, making the results unreliable. I secured a remote testing machine in order to run the experiments in complete isolation. Here, at first, they were running on an NFS mounted drive, meaning that network latency and protocol overheads were affecting the results. After moving the experiments to local disk, it was clear that ORAM overheads were finally dominating the results. Now, secondly, I needed to initialise the ORAMs properly. Using a fresh ORAM, the stash is empty and most of the blocks are dummy blocks that get disregarded. It is necessary to run an initialisation sequence in order to remove the effects of these on the results. We use the worst case sequence, writing each block in turn, then reading each block in turn, to ensure that all blocks get used multiple times, leaving the ORAM in a state that it would likely be in after extended use. Only once this steady state has been reached can we reliably test the performance.

For the actual experiment, rather than using the worst case sequence, we use a random sequence of block accesses. We perform 10,000 iterations, oscillating between reads and writes in order to balance the different overheads. We are trying to see how the performance changes as the block size increases, so we use ORAMs of a range of sizes, from 12 blocks (a tree of depth 1) to 8188 blocks (a tree of depth 10). The log of the time taken for each ORAM to perform 10,000 iterations is plotted against the logarithm of the size of the ORAM in \cref{fig:timePlot}. We expect this to be a straight line, because we expect logarithmic overheads from ORAM, and we increase the block sizes roughly in powers of two.

\mytodo{Add further close analysis of the actual results}

The initialisation phase allowed the stash size to reach a steady state, which resulted in a constant overhead of $x$ blocks, compared with $y$ predicted in \cite{stefanov2013path} for a security parameter, $\lambda = z$. This shows something...

In these first experiments, we used stateless, non-recursive ORAM, which means that the entire of the position map was being flushed to disk on every access. We now compare the time taken for stateless, recursive ORAM, to see what effect the additional recursive calls have compared to the reduction in the size of the client side state. We can see from \cref{fig:recursiveTimePlot} that overall this was good/bad to some degree.

Although it has not been discussed here, bandwidth is another important measure when examining the performance of ORAM, especially when it is being used in the cloud. With more time, a detailed study of the bandwidth used with and without recursion would have been carried out, which would have given further insight into the trade-off that recursion presents us with. We also could have examined the proportion of the overall performance overhead that was contributed by encryption.

\section{Security Analysis}
\label{sec:securityAnalysis}

In order to test the security of ORAM, we need to show that the access pattern observed by the block device is actually statistically random. Of course there is structure to this randomness, because on each access a whole path is read and written, but the actual path that gets written should be random. Thus, we should perform a test for randomness on an actual sequence of path indices. We are in effect testing OCaml's Random library for pseudo-randomness, because the security of our construction relies on it. Taking a 10,000 iteration pattern from the largest block device yielded the following results, that show that it is indeed random to within some significant statistical degree that I don't understand yet.

\mytodo{Redo this based on actual method and results}

\chapter{Conclusions}

\section{Results}

\mytodo{Write the results section based on actual results}

\section{Lessons Learnt}

This project has taught me many important lessons. The one that has had the most impact is time management. I got stuck into the project straight away and did as much work on it as I could during the Michaelmas term and vacation, which meant that hiccoughs later down the line had a large buffer and didn't cause severe consequences. Related to this I learnt that predicting the time that each part of a project will take is very difficult and it is therefore important to be both conservative and realistic about the number of things that will go wrong. Finally, I learnt that you should seek advice as soon as there are signs of trouble, rather than waiting for a scheduled meeting to brings something up. The advice of experienced supervisors can turn the seemingly catastrophic into a minor disruption.

\section{Future Work}

There is still much work to be done in the field of ORAM. One of the main drawbacks of current schemes is that the size of the ORAM must be determined in advance and the overhead associated with expanding it is enormous. I would like to investigate the possibility of creating a resizable version of my implementation, however this was unfortunately not in the scope of this project.

There are also many optimisations to be performed on this implementation. Along with many interesting optimisations mentioned in the literature, there is of course plenty of room for analysis and optimisation of this specific implementation using benchmarking to identify code hot-spots. This would of course only reduce the constants involved in the performance, rather than providing an asymptotic improvement.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix

\chapter{Project Proposal}

\input{proposal}

\end{document}
